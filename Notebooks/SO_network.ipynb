{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "apart-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "previous-navigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "casual-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees, user_data, post_data, chosen_uids, chosen_trees = pickle.load(open('so_politics.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "civilian-boutique",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15302, 1456, 552)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trees), len(chosen_trees), len(chosen_uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "passive-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAA(pid):\n",
    "    if post_data[pid]['type'] in [1,3]: return False\n",
    "    rid = post_data[pid]['rootid']\n",
    "    if math.isnan(post_data[rid]['accepted_answer_id']): return False\n",
    "    return post_data[rid]['accepted_answer_id']==pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "swedish-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_null(d1):\n",
    "    d = deepcopy(d1)\n",
    "    for k,v in list(d.items()):\n",
    "        if not v:\n",
    "            d[k]=\"N/A\"\n",
    "        elif k=='tags' and type(v)==list:\n",
    "            d[k] = ' - '.join(v)\n",
    "        elif type(v)==list:\n",
    "#             print(k)\n",
    "            del d[k]\n",
    "        else:\n",
    "            d[k]=str(v)\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "annoying-banner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1456/1456 [00:00<00:00, 2239.25it/s]\n"
     ]
    }
   ],
   "source": [
    "edges = []\n",
    "max_len = 0\n",
    "max_rid = -1\n",
    "node_attr = defaultdict(dict)\n",
    "user_tags = defaultdict(set)\n",
    "user_posts = defaultdict(list)\n",
    "all_tags=set()\n",
    "for rid in tqdm(chosen_trees):\n",
    "    \n",
    "    cur_tree = trees[rid]\n",
    "    tags = post_data[rid]['tags']\n",
    "    all_tags.update(tags)\n",
    "    tmp_len=0\n",
    "    for pid in cur_tree:\n",
    "        if post_data[pid]['user_id'] in chosen_uids:\n",
    "            uid = 'u'+str(int(post_data[pid]['user_id']))\n",
    "            user_posts[uid].append(post_data[pid]['text'])\n",
    "    for edge in cur_tree.edges():\n",
    "        p1 = post_data[edge[0]]\n",
    "        p2 = post_data[edge[1]]\n",
    "        if post_data[edge[0]]['user_id'] not in chosen_uids or \\\n",
    "            post_data[edge[1]]['user_id'] not in chosen_uids: continue\n",
    "        t1 = post_data[edge[0]]['type']\n",
    "        t2 = post_data[edge[1]]['type']\n",
    "        u1 = 'u'+str(int(post_data[edge[0]]['user_id']))\n",
    "        u2 = 'u'+str(int(post_data[edge[1]]['user_id']))\n",
    "        edge = (str(edge[0]), str(edge[1]))\n",
    "        \n",
    "        \n",
    "        user_tags[u1].update(tags)\n",
    "        user_tags[u2].update(tags)\n",
    "        \n",
    "        if t1==1 and t2==2:\n",
    "            node_attr[edge[1]]['AA'] = checkAA(int(edge[1]))\n",
    "            edges.append(edge)#+({'type':'A'},))\n",
    "            edges.append((u1,edge[0]))#,{'type':'OP'}))\n",
    "            edges.append((u2,edge[1]))#,{'type':'Contributor'}))\n",
    "        elif t1==1 and t2==3:\n",
    "            edges.append(edge)#+({'type':'C'},))\n",
    "            edges.append((u1,edge[0]))#,{'type':'OP'}))\n",
    "            edges.append((u2,edge[1]))#,{'type':'Contributor'}))\n",
    "        elif t1==2 and t2==3:\n",
    "            node_attr[edge[0]]['AA'] = checkAA(int(edge[0]))\n",
    "            edges.append(edge)#+({'type':'C'},))\n",
    "            edges.append((u1,edge[0]))#,{'type':'Contributor'}))\n",
    "            edges.append((u2,edge[1]))#,{'type':'Contributor'}))\n",
    "        else:\n",
    "            print(t1,t2)\n",
    "        tmp_len+=1\n",
    "        node_attr[u1] = user_data[p1['user_id']]\n",
    "        node_attr[u2] = user_data[p2['user_id']]\n",
    "        node_attr[edge[0]].update(p1)\n",
    "        node_attr[edge[1]].update(p2)\n",
    "    if tmp_len>max_len:\n",
    "        max_len = tmp_len\n",
    "        max_rid=rid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "subject-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "greater-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, node_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hundred-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_und = G.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "provincial-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nei_nodes(nid, dep=3):\n",
    "    queue = []\n",
    "    visited = set()\n",
    "    queue.append([nid,0])\n",
    "    visited.add(nid)\n",
    "    \n",
    "    nids = []\n",
    "    while queue:\n",
    "        src = queue.pop(0)\n",
    "        nids.append(src[0])\n",
    "        if src[1]<dep:\n",
    "            for sibid in nx.all_neighbors(G_und, src[0]):\n",
    "                if sibid not in visited:\n",
    "                    queue.append([sibid, src[1]+1])\n",
    "                    visited.add(sibid)\n",
    "    return nids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "virgin-spain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "844 1026\n",
      "2050 2688\n",
      "152 184\n",
      "354 468\n",
      "1135 1386\n"
     ]
    }
   ],
   "source": [
    "for i in random.sample(G.nodes(),5):\n",
    "    sub_nodes=get_nei_nodes(i,3)\n",
    "    sub_G = G.subgraph(sub_nodes)\n",
    "    print(len(sub_G), len(sub_G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cutting-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nx.write_gexf(G.subgraph(sub_nodes), \"so_politics.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-increase",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "threaded-james",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nirmal/miniconda3/envs/OPT/lib/python3.8/site-packages/huggingface_hub/file_download.py:637: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  warnings.warn(\n",
      "2023-05-06 03:36:21.516442: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/lib:/usr/lib:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/lib:/usr/lib:\n",
      "2023-05-06 03:36:21.516615: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/lib:/usr/lib:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/lib:/usr/lib:\n",
      "2023-05-06 03:36:21.516627: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Maximum Sequence Length:  384\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', {'cache_dir':'/data/huggingface_cache'}).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "transsexual-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_uids = [i for i in node_attr.keys() if i[0]=='u']\n",
    "all_uid_id = {j:i for i,j in enumerate(all_uids)}\n",
    "all_pids = [i for i in node_attr.keys() if i[0]!='u']\n",
    "all_pid_id = {j:i for i,j in enumerate(all_pids)}\n",
    "all_tags = list(all_tags)\n",
    "all_tag_id = {j:i for i,j in enumerate(all_tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "undefined-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_posts = [post_data[int(i) if i[0]!='c' else i]['text'] for i in all_pids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "realistic-probe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 552/552 [09:08<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "user_embs = np.array([model.encode(user_posts[i]).mean(0) for i in tqdm(all_uids)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "intensive-rebecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████| 339/339 [05:37<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "post_embs = model.encode(all_posts, show_progress_bar=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "stuck-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples = []\n",
    "for uid,u_tags in user_tags.items():    \n",
    "    for u_tag in u_tags:\n",
    "        row = []\n",
    "        row.append([ all_uid_id[uid], all_tag_id[u_tag]])\n",
    "        negs = random.sample(set(all_tags)-u_tags,10)\n",
    "        for n in negs:\n",
    "            row.append([all_uid_id[uid], all_tag_id[n]])\n",
    "        training_samples.append(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "diagnostic-cemetery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29866"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "subsequent-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([all_uids, user_emb, all_pids, post_embs], open('./so_net_data.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "optical-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_post_edges = set()\n",
    "all_user_user_edges = set()\n",
    "user_to_posts = defaultdict(set)\n",
    "user_to_users = defaultdict(set)\n",
    "for u,v,d in G.edges(data=True):\n",
    "    if u[0]=='u':\n",
    "        all_user_post_edges.add(tuple(sorted((u,v))))\n",
    "        user_to_posts[u].add(v)\n",
    "        \n",
    "        for nid in nx.all_neighbors(G, v):\n",
    "            if nid[0]!='u':\n",
    "                for uid in nx.all_neighbors(G, nid):\n",
    "                    if uid[0]=='u' and uid!=u:\n",
    "                        all_user_user_edges.add(tuple(sorted((u,uid))))\n",
    "                        user_to_users[u].add(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fifth-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in all_user_post_edges:\n",
    "    assert nx.shortest_path_length(G_und,a,b)==1\n",
    "for a,b in all_user_user_edges:\n",
    "    assert nx.shortest_path_length(G_und,a,b)==3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "marked-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.shortest_path_length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "designing-carbon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43284, 12232)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_user_post_edges), len(all_user_user_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "willing-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_user_samples = []\n",
    "for uid, p_uids in user_to_users.items():\n",
    "    for p_uid in p_uids:\n",
    "        row=[]\n",
    "        row.append([all_uid_id[uid], all_uid_id[p_uid]])\n",
    "        n_uids = random.sample(set(all_uids)-p_uids,10)\n",
    "        row += [[all_uid_id[uid], all_uid_id[nuid]] for nuid in n_uids] \n",
    "        user_user_samples.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "outside-athletics",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 552/552 [00:09<00:00, 59.23it/s]\n"
     ]
    }
   ],
   "source": [
    "user_post_samples = []\n",
    "for uid, p_uids in tqdm(user_to_posts.items()):\n",
    "#     print(len(p_uids))\n",
    "    for p_uid in p_uids:\n",
    "        row=[]\n",
    "        row.append([all_uid_id[uid], all_pid_id[p_uid]])\n",
    "        n_uids = random.sample(set(random.sample(all_pids,len(p_uids)+10))-p_uids,5)\n",
    "        row += [[all_uid_id[uid], all_pid_id[nuid]] for nuid in n_uids]\n",
    "        user_post_samples.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "occupied-measure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43284, 24464)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_post_samples), len(user_user_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ruled-links",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.360864"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "67.07*0.22*0.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "upper-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([all_uids, user_emb, all_pids, post_embs, user_user_samples, user_post_samples],\\\n",
    "            open('./so_tr_data.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "collect-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers.util import cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "insured-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wgts = torch.load('./Models/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "compact-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_embs = model_wgts['node_embeddings.weight']\n",
    "train_post_embs = model_wgts['word_embeddings.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "reduced-cancer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([552, 768]), (552, 768), (43284, 768), torch.Size([43284, 768]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_embs.shape, user_emb.shape, post_embs.shape, train_post_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "greenhouse-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_post_cos = cos_sim(user_emb, post_embs)\n",
    "tr_user_post_cos = cos_sim(train_user_embs, train_post_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "focused-queens",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 552/552 [00:03<00:00, 165.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.023813022739192925, 0.020648614608151174)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac1=[]\n",
    "jac2=[]\n",
    "for uid, p_pids in tqdm(user_to_posts.items()):\n",
    "    uid = all_uid_id[uid]\n",
    "    p_pids = set([all_pid_id[i] for i in p_pids])\n",
    "    pred1 = set((-user_post_cos[uid]).argsort()[:10].tolist())\n",
    "    pred2 = set((-tr_user_post_cos[uid]).argsort()[:10].tolist())\n",
    "    \n",
    "    jac1.append(len(p_pids&pred1)/len(p_pids|pred1))\n",
    "    jac2.append(len(p_pids&pred2)/len(p_pids|pred2))\n",
    "    \n",
    "np.mean(jac1), np.mean(jac2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "inner-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_user_cos = cos_sim(user_emb, user_emb)\n",
    "tr_user_user_cos = cos_sim(train_user_embs, train_user_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "elementary-miami",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 552/552 [00:00<00:00, 561.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06063541316893815, 0.03193194002743345)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac1=[]\n",
    "jac2=[]\n",
    "for uid, p_uids in tqdm(user_to_users.items()):\n",
    "    uid = all_uid_id[uid]\n",
    "    p_uids = set([all_uid_id[i] for i in p_uids])\n",
    "    pred1 = set((-user_user_cos[uid]).argsort()[:10].tolist())\n",
    "    pred2 = set((-tr_user_user_cos[uid]).argsort()[:10].tolist())\n",
    "    \n",
    "    jac1.append(len(p_uids&pred1)/len(p_uids|pred1))\n",
    "    jac2.append(len(p_uids&pred2)/len(p_uids|pred2))\n",
    "    \n",
    "np.mean(jac1), np.mean(jac2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OPT",
   "language": "python",
   "name": "opt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
